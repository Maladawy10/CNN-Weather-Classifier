{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-05-24T17:08:43.286323Z","iopub.execute_input":"2022-05-24T17:08:43.286659Z","iopub.status.idle":"2022-05-24T17:08:43.309067Z","shell.execute_reply.started":"2022-05-24T17:08:43.286580Z","shell.execute_reply":"2022-05-24T17:08:43.308393Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"imgsize = (224,224)\ntrainfolder= './Train/'\n# trainfolder=\"/kaggle/input/nn22-weather-analysis-using-image-recognition/Dataset/Train/\"\nbatch_size = 64\naug_factor = 1\nsub_dir=['dew','fogsmog','frost','glaze','hail',\n         'lightning','rain','rainbow','rime','sandstorm','snow']\nTRAIN_DIR=\"/kaggle/input/nn22-weather-analysis-using-image-recognition/Dataset/Train/\"\n","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:39:26.455189Z","iopub.execute_input":"2022-05-24T22:39:26.455776Z","iopub.status.idle":"2022-05-24T22:39:26.477086Z","shell.execute_reply.started":"2022-05-24T22:39:26.455681Z","shell.execute_reply":"2022-05-24T22:39:26.476388Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\nimport tensorflow as tf\nimport tqdm","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:39:27.733498Z","iopub.execute_input":"2022-05-24T22:39:27.734192Z","iopub.status.idle":"2022-05-24T22:39:32.090051Z","shell.execute_reply.started":"2022-05-24T22:39:27.734157Z","shell.execute_reply":"2022-05-24T22:39:32.089113Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\n\nsub_dir_aug = []\nsub_dir_sizes = []\nmax_class = 0\nfor sub_file in sub_dir :\n    sub=TRAIN_DIR+sub_file\n    size=len(os.listdir(sub))\n    sub_dir_sizes.append(size)\n    if size > max_class :\n        max_class = size\nprint (max_class)\n\nfor size in sub_dir_sizes :\n    sub_dir_aug.append(round(max_class*aug_factor/size))\nsub_dir_aug","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:39:32.091928Z","iopub.execute_input":"2022-05-24T22:39:32.092177Z","iopub.status.idle":"2022-05-24T22:39:32.605333Z","shell.execute_reply.started":"2022-05-24T22:39:32.092143Z","shell.execute_reply":"2022-05-24T22:39:32.604598Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"1059\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[2, 1, 3, 2, 2, 4, 3, 8, 1, 2, 2]"},"metadata":{}}]},{"cell_type":"code","source":"import os\ndef create_output_path() :\n    output_path = './'\n    dire=''\n    if os.path.isdir(output_path+\"Train\")==False :\n        os.mkdir(output_path+\"Train\")\n    output_path = './Train/'\n    for i in range(len(sub_dir)) :\n        dire=output_path+sub_dir[i]\n        if os.path.isdir(dire)==False :\n            os.mkdir(output_path+sub_dir[i])\n    return output_path","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:39:33.734482Z","iopub.execute_input":"2022-05-24T22:39:33.735045Z","iopub.status.idle":"2022-05-24T22:39:33.740869Z","shell.execute_reply.started":"2022-05-24T22:39:33.735006Z","shell.execute_reply":"2022-05-24T22:39:33.740031Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nimport numpy as np\nimport cv2\naug = ImageDataGenerator(\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n#     vertical_flip=True,\n    fill_mode=\"nearest\")\n\ndef single_data_over_sampling(imagename , total , saved_dir,aug=aug) :\n    image = load_img(imagename)\n    image = img_to_array(image)\n    image = np.expand_dims(image, axis=0)\n\n    imageGen = aug.flow(image, batch_size=1, save_to_dir=saved_dir,\n        save_prefix=\"image\", save_format=\"jpg\")\n    # loop over examples from our image data augmentation generator\n    i=0\n    for image in imageGen:\n        # increment our counter\n        i += 1\n        # if we have reached the specified number of examples, break\n        # from the loop\n        if i == total:\n            break","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:39:35.457532Z","iopub.execute_input":"2022-05-24T22:39:35.457791Z","iopub.status.idle":"2022-05-24T22:39:36.608067Z","shell.execute_reply.started":"2022-05-24T22:39:35.457760Z","shell.execute_reply":"2022-05-24T22:39:36.607343Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# sub_dir_aug\n# TRAIN_DIR\n# sub_dir\nimport os\noutput_path = create_output_path()\ndef data_over_sampling():\n    for i in range(len(sub_dir)) :\n        sub = TRAIN_DIR+sub_dir[i]\n        images = os.listdir(sub)\n        for image in images :\n            single_data_over_sampling(sub+'/'+image , sub_dir_aug[i] , output_path+sub_dir[i])","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:39:37.646092Z","iopub.execute_input":"2022-05-24T22:39:37.646352Z","iopub.status.idle":"2022-05-24T22:39:37.655282Z","shell.execute_reply.started":"2022-05-24T22:39:37.646322Z","shell.execute_reply":"2022-05-24T22:39:37.654211Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_over_sampling()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:39:39.488645Z","iopub.execute_input":"2022-05-24T22:39:39.489061Z","iopub.status.idle":"2022-05-24T22:52:47.505870Z","shell.execute_reply.started":"2022-05-24T22:39:39.489023Z","shell.execute_reply":"2022-05-24T22:52:47.505141Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for sub_file in sub_dir :\n    sub=trainfolder+sub_file\n    size=len(os.listdir(sub))\n    print(size)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:00.963790Z","iopub.execute_input":"2022-05-24T22:54:00.964236Z","iopub.status.idle":"2022-05-24T22:54:00.983693Z","shell.execute_reply.started":"2022-05-24T22:54:00.964192Z","shell.execute_reply":"2022-05-24T22:54:00.983030Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"1052\n721\n956\n1029\n849\n1057\n1109\n1001\n1006\n1042\n987\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nTRAIN_DATAGEN = ImageDataGenerator(rescale = 1./255.,\n                                  rotation_range = 40,\n                                  width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   validation_split=0.2,\n                                    vertical_flip=True,\n                                   horizontal_flip = True,\n                                    fill_mode='nearest',\n                                   \n                                  )\nVALID_DATAGEN = ImageDataGenerator(rescale = 1./255.,\n                                  rotation_range = 40,\n                                  width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   validation_split=0.2,\n                                    vertical_flip=True,\n                                    horizontal_flip = True,\n                                   fill_mode='nearest',\n                                   \n                                  )\n\n\nTRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = trainfolder,\n                                                    batch_size = batch_size,\n                                                    target_size = imgsize,\n                                                    subset = 'training',\n                                                    color_mode='rgb',\n                                                    seed = 123)\n\nVALIDATION_GENERATOR = VALID_DATAGEN.flow_from_directory(directory = trainfolder,\n                                                        batch_size = batch_size, \n                                                        target_size = imgsize,\n                                                        subset = 'validation',\n                                                        color_mode='rgb',\n                                                        seed = 123)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:01.820324Z","iopub.execute_input":"2022-05-24T22:54:01.820587Z","iopub.status.idle":"2022-05-24T22:54:02.567334Z","shell.execute_reply.started":"2022-05-24T22:54:01.820557Z","shell.execute_reply":"2022-05-24T22:54:02.566604Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 8652 images belonging to 11 classes.\nFound 2157 images belonging to 11 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from collections import Counter\ncounter = Counter(TRAIN_GENERATOR.classes)                          \nmax_val = float(max(counter.values()))       \nclass_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}                     ","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:02.568957Z","iopub.execute_input":"2022-05-24T22:54:02.569389Z","iopub.status.idle":"2022-05-24T22:54:02.577062Z","shell.execute_reply.started":"2022-05-24T22:54:02.569351Z","shell.execute_reply":"2022-05-24T22:54:02.576395Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# # from tflearn.layers.conv import conv_2d, max_pool_2d\n# # from tflearn.layers.core import input_data, dropout, fully_connected\n# # from tflearn.layers.estimator import regression\n# # from sklearn.model_selection import train_test_split\n# # X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=1,shuffle=True)\n\n# from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Reshape , Conv2D,MaxPooling2D,Dropout,UpSampling2D,concatenate,BatchNormalization\n# from tensorflow.keras.models import Model\n# from tensorflow.keras import optimizers, losses, metrics,regularizers\n\n# kernel_initializer = 'he_normal'\n# def model(shape):\n    \n# #     conv_input = input_data(shape=[None, 256, 256, 3], name='input')\n#     inputs = Input(shape)\n#     conv1 = Conv2D( 32, 5, activation='relu',padding = 'same', kernel_initializer = kernel_initializer)(inputs)\n#     pool1 = MaxPooling2D(5)(conv1)\n\n#     conv2 = Conv2D( 64, 5, activation='relu',padding = 'same', kernel_initializer = kernel_initializer)(pool1)\n#     pool2 = MaxPooling2D( 5)(conv2)\n\n#     conv3 = Conv2D( 128, 5, activation='relu',padding = 'same', kernel_initializer = kernel_initializer)(pool2)\n#     pool3 = MaxPooling2D( 5)(conv3)\n\n#     conv4 = Conv2D( 64, 5, activation='relu',padding = 'same', kernel_initializer = kernel_initializer)(pool3)\n#     pool4 = MaxPooling2D(5,padding = 'same')(conv4)\n\n#     conv5 = Conv2D( 32, 5, activation='relu',padding = 'same', kernel_initializer = kernel_initializer)(pool4)\n#     pool5 = MaxPooling2D(5,padding = 'same')(conv5)\n    \n#     flatten = Flatten()(pool5)\n    \n#     fully_layer = Dense( 1024, activation='relu', kernel_initializer = kernel_initializer)(flatten)\n#     fully_layer = Dropout( 0.5)(fully_layer)\n\n#     cnn_layers = Dense( 11, activation='softmax')(fully_layer)\n\n# #     cnn_layers = regression(cnn_layers, optimizer='adam', learning_rate=0.001, loss='categorical_crossentropy', name='targets')\n# #     model = tflearn.DNN(cnn_layers, tensorboard_dir='log', tensorboard_verbose=3)\n#     return  Model(inputs, cnn_layers)","metadata":{"id":"M8TXyfF9E5ST","execution":{"iopub.status.busy":"2022-05-24T22:54:02.590173Z","iopub.execute_input":"2022-05-24T22:54:02.590384Z","iopub.status.idle":"2022-05-24T22:54:02.595099Z","shell.execute_reply.started":"2022-05-24T22:54:02.590360Z","shell.execute_reply":"2022-05-24T22:54:02.594034Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def covidmodel(shape) :\n    # Creating a Sequential Model and adding the layers\n    modelXCOVID1 = Sequential()\n    modelXCOVID1.add(Conv2D(filters=32, input_shape=shape, kernel_size=(11,11), strides=(4,4), padding='valid'))\n    modelXCOVID1.add(Activation('relu'))\n    #Add bTCH NORMALIZATION LAYER \n    #BatchNormalization(axis=1)\n    modelXCOVID1.add(MaxPooling2D(pool_size=(2,2)))\n    modelXCOVID1.add(Conv2D(filters=64, kernel_size=(3,3)))\n    modelXCOVID1.add(Activation('relu'))\n    #Add bTCH NORMALIZATION LAYER \n    #BatchNormalization(axis=1)\n    modelXCOVID1.add(MaxPooling2D(pool_size=(2, 2)))\n    modelXCOVID1.add(Conv2D(128, kernel_size=(3,3) ))\n    modelXCOVID1.add(Activation('relu'))\n    #Add bTCH NORMALIZATION LAYER \n    #BatchNormalization(axis=1)\n    modelXCOVID1.add(MaxPooling2D(pool_size=(2, 2)))\n    modelXCOVID1.add(Flatten())\n    # 1st Fully Connected Layer\n    modelXCOVID1.add(Dense(512))\n    modelXCOVID1.add(Activation('relu'))\n    # Add Dropout to prevent overfitting\n    modelXCOVID1.add(Dropout(0.4))\n    # 2rd Fully Connected Layer\n    modelXCOVID1.add(Dense(64))\n    modelXCOVID1.add(Activation('relu'))\n    # Add Dropout to prevent overfitting\n    modelXCOVID1.add(Dropout(0.4))\n    # Passing it to a Fully Connected layer\n\n    # Output Layer\n    modelXCOVID1.add(Dense(11))\n    modelXCOVID1.add(Activation('softmax'))\n    \n    return modelXCOVID1\n","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:02.905402Z","iopub.execute_input":"2022-05-24T22:54:02.906150Z","iopub.status.idle":"2022-05-24T22:54:02.915528Z","shell.execute_reply.started":"2022-05-24T22:54:02.906100Z","shell.execute_reply":"2022-05-24T22:54:02.914750Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D , Flatten\nfrom tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Reshape , Conv2D,MaxPooling2D,Dropout,UpSampling2D,concatenate,BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import optimizers, losses, metrics,regularizers\ndef vgg(shape):\n    model = Sequential()\n    model.add(Conv2D(input_shape=shape,filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    model.add(Flatten())\n#     model.add(Dense(units=4096,activation=\"relu\"))\n#     model.add(Dense(units=1024,activation=\"relu\"))\n    model.add(Dense(units=11, activation=\"softmax\"))\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:03.177716Z","iopub.execute_input":"2022-05-24T22:54:03.177988Z","iopub.status.idle":"2022-05-24T22:54:03.196168Z","shell.execute_reply.started":"2022-05-24T22:54:03.177957Z","shell.execute_reply":"2022-05-24T22:54:03.195376Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\nimport keras\nfrom keras.models import Sequential, Model,load_model\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\nfrom keras.preprocessing import image\nfrom keras.initializers import glorot_uniform","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:03.534236Z","iopub.execute_input":"2022-05-24T22:54:03.534760Z","iopub.status.idle":"2022-05-24T22:54:03.540334Z","shell.execute_reply.started":"2022-05-24T22:54:03.534721Z","shell.execute_reply":"2022-05-24T22:54:03.539512Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def identity_block(X, f, filters, stage, block):\n   \n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    F1, F2, F3 = filters\n\n    X_shortcut = X\n   \n    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    X = Add()([X, X_shortcut])# SKIP Connection\n    X = Activation('relu')(X)\n\n    return X\ndef convolutional_block(X, f, filters, stage, block, s=2):\n   \n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    F1, F2, F3 = filters\n\n    X_shortcut = X\n\n    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X\ndef ResNet50(input_shape=(224, 224, 3)):\n\n    X_input = Input(input_shape)\n\n    X = ZeroPadding2D((3, 3))(X_input)\n\n    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n\n    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n\n    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n    \n    X = Flatten()(X)\n#     X = Dense( 2048, activation='relu', kernel_initializer=glorot_uniform(seed=0))(X)\n#     X = Dropout( 0.5)(X)\n    X = Dense( 1024, activation='relu', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = Dropout( 0.5)(X)\n    \n    X = Dense( 11, activation='softmax')(X)\n\n    \n    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:03.881700Z","iopub.execute_input":"2022-05-24T22:54:03.882183Z","iopub.status.idle":"2022-05-24T22:54:03.911082Z","shell.execute_reply.started":"2022-05-24T22:54:03.882145Z","shell.execute_reply":"2022-05-24T22:54:03.910297Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.layers.core import Layer\nimport keras.backend as K\nimport tensorflow as tf\nfrom keras.datasets import cifar10\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPool2D,  \\\n    Dropout, Dense, Input, concatenate,      \\\n    GlobalAveragePooling2D, AveragePooling2D,\\\n    Flatten\n\nimport cv2 \nimport numpy as np \nfrom keras.datasets import cifar10 \nfrom keras import backend as K \nfrom keras.utils import np_utils\n\nimport math \n# from keras.optimizers import SGD \n# from keras.callbacks import LearningRateScheduler\ndef inception_module(x,\n                     filters_1x1,\n                     filters_3x3_reduce,\n                     filters_3x3,\n                     filters_5x5_reduce,\n                     filters_5x5,\n                     filters_pool_proj,\n                     name=None):\n    \n    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n    \n    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3)\n\n    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5)\n\n    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n\n    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n    \n    return output\nkernel_init = keras.initializers.glorot_uniform()\nbias_init = keras.initializers.Constant(value=0.2)\ndef inception(shape):\n    input_layer = Input(shape=shape)\n\n    x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2', kernel_initializer=kernel_init, bias_initializer=bias_init)(input_layer)\n    x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n    x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n    x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n    x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n\n    x = inception_module(x,\n                         filters_1x1=64,\n                         filters_3x3_reduce=96,\n                         filters_3x3=128,\n                         filters_5x5_reduce=16,\n                         filters_5x5=32,\n                         filters_pool_proj=32,\n                         name='inception_3a')\n\n    x = inception_module(x,\n                         filters_1x1=128,\n                         filters_3x3_reduce=128,\n                         filters_3x3=192,\n                         filters_5x5_reduce=32,\n                         filters_5x5=96,\n                         filters_pool_proj=64,\n                         name='inception_3b')\n\n    x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n\n    x = inception_module(x,\n                         filters_1x1=192,\n                         filters_3x3_reduce=96,\n                         filters_3x3=208,\n                         filters_5x5_reduce=16,\n                         filters_5x5=48,\n                         filters_pool_proj=64,\n                         name='inception_4a')\n\n\n    x1 = AveragePooling2D((5, 5), strides=3)(x)\n    x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\n    x1 = Flatten()(x1)\n    x1 = Dense(1024, activation='relu')(x1)\n    x1 = Dropout(0.7)(x1)\n    x1 = Dense(11, activation='softmax', name='auxilliary_output_1')(x1)\n\n    x = inception_module(x,\n                         filters_1x1=160,\n                         filters_3x3_reduce=112,\n                         filters_3x3=224,\n                         filters_5x5_reduce=24,\n                         filters_5x5=64,\n                         filters_pool_proj=64,\n                         name='inception_4b')\n\n    x = inception_module(x,\n                         filters_1x1=128,\n                         filters_3x3_reduce=128,\n                         filters_3x3=256,\n                         filters_5x5_reduce=24,\n                         filters_5x5=64,\n                         filters_pool_proj=64,\n                         name='inception_4c')\n\n    x = inception_module(x,\n                         filters_1x1=112,\n                         filters_3x3_reduce=144,\n                         filters_3x3=288,\n                         filters_5x5_reduce=32,\n                         filters_5x5=64,\n                         filters_pool_proj=64,\n                         name='inception_4d')\n\n\n    x2 = AveragePooling2D((5, 5), strides=3)(x)\n    x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n    x2 = Flatten()(x2)\n    x2 = Dense(1024, activation='relu')(x2)\n    x2 = Dropout(0.7)(x2)\n    x2 = Dense(11, activation='softmax', name='auxilliary_output_2')(x2)\n\n    x = inception_module(x,\n                         filters_1x1=256,\n                         filters_3x3_reduce=160,\n                         filters_3x3=320,\n                         filters_5x5_reduce=32,\n                         filters_5x5=128,\n                         filters_pool_proj=128,\n                         name='inception_4e')\n\n    x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n\n    x = inception_module(x,\n                         filters_1x1=256,\n                         filters_3x3_reduce=160,\n                         filters_3x3=320,\n                         filters_5x5_reduce=32,\n                         filters_5x5=128,\n                         filters_pool_proj=128,\n                         name='inception_5a')\n\n    x = inception_module(x,\n                         filters_1x1=384,\n                         filters_3x3_reduce=192,\n                         filters_3x3=384,\n                         filters_5x5_reduce=48,\n                         filters_5x5=128,\n                         filters_pool_proj=128,\n                         name='inception_5b')\n\n    x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n    \n#     x = Dense( 2048, activation='relu', kernel_initializer=glorot_uniform(seed=0))(x)\n#     x = Dropout( 0.5)(x)\n#     x = Dense( 1024, activation='relu', kernel_initializer=glorot_uniform(seed=0))(x)\n#     x = Dropout( 0.5)(x)\n\n    x = Dropout(0.5)(x)\n\n    x = Dense(11, activation='softmax', name='output')(x)\n    \n    return Model(input_layer, [x, x1, x2], name='inception_v1')\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:04.354261Z","iopub.execute_input":"2022-05-24T22:54:04.354761Z","iopub.status.idle":"2022-05-24T22:54:04.386115Z","shell.execute_reply.started":"2022-05-24T22:54:04.354726Z","shell.execute_reply":"2022-05-24T22:54:04.385394Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"ince=False\n# model = model((224, 224, 3))\n# model = vgg((224, 224, 3))\n# model = covidmodel((224, 224, 3))\nmodel = ResNet50((224, 224, 3))\n# model = inception((224, 224, 3))\n# ince=True\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:04.828368Z","iopub.execute_input":"2022-05-24T22:54:04.828616Z","iopub.status.idle":"2022-05-24T22:54:08.251292Z","shell.execute_reply.started":"2022-05-24T22:54:04.828587Z","shell.execute_reply":"2022-05-24T22:54:08.250560Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"2022-05-24 22:54:04.934134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-24 22:54:05.057979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-24 22:54:05.058798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-24 22:54:05.060140: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-05-24 22:54:05.060426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-24 22:54:05.061217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-24 22:54:05.061912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-24 22:54:06.996235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-24 22:54:06.997034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-24 22:54:06.997682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-24 22:54:06.999192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Model: \"ResNet50\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\nzero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n__________________________________________________________________________________________________\nconv1 (Conv2D)                  (None, 112, 112, 64) 9472        zero_padding2d[0][0]             \n__________________________________________________________________________________________________\nbn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation[0][0]                 \n__________________________________________________________________________________________________\nres2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nbn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n__________________________________________________________________________________________________\nres2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_1[0][0]               \n__________________________________________________________________________________________________\nbn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n__________________________________________________________________________________________________\nres2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_2[0][0]               \n__________________________________________________________________________________________________\nres2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nbn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n__________________________________________________________________________________________________\nbn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n__________________________________________________________________________________________________\nadd (Add)                       (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n                                                                 bn2a_branch1[0][0]               \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n__________________________________________________________________________________________________\nres2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_3[0][0]               \n__________________________________________________________________________________________________\nbn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n__________________________________________________________________________________________________\nres2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_4[0][0]               \n__________________________________________________________________________________________________\nbn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n__________________________________________________________________________________________________\nres2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_5[0][0]               \n__________________________________________________________________________________________________\nbn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n                                                                 activation_3[0][0]               \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n__________________________________________________________________________________________________\nres2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_6[0][0]               \n__________________________________________________________________________________________________\nbn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n__________________________________________________________________________________________________\nres2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_7[0][0]               \n__________________________________________________________________________________________________\nbn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n__________________________________________________________________________________________________\nres2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_8[0][0]               \n__________________________________________________________________________________________________\nbn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n                                                                 activation_6[0][0]               \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n__________________________________________________________________________________________________\nres3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_9[0][0]               \n__________________________________________________________________________________________________\nbn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n__________________________________________________________________________________________________\nres3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_10[0][0]              \n__________________________________________________________________________________________________\nbn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n__________________________________________________________________________________________________\nres3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_11[0][0]              \n__________________________________________________________________________________________________\nres3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_9[0][0]               \n__________________________________________________________________________________________________\nbn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n__________________________________________________________________________________________________\nbn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n                                                                 bn3a_branch1[0][0]               \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n__________________________________________________________________________________________________\nres3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_12[0][0]              \n__________________________________________________________________________________________________\nbn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n__________________________________________________________________________________________________\nres3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_13[0][0]              \n__________________________________________________________________________________________________\nbn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n__________________________________________________________________________________________________\nres3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_14[0][0]              \n__________________________________________________________________________________________________\nbn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n                                                                 activation_12[0][0]              \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n__________________________________________________________________________________________________\nres3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_15[0][0]              \n__________________________________________________________________________________________________\nbn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n__________________________________________________________________________________________________\nres3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_16[0][0]              \n__________________________________________________________________________________________________\nbn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n__________________________________________________________________________________________________\nres3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_17[0][0]              \n__________________________________________________________________________________________________\nbn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n                                                                 activation_15[0][0]              \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n__________________________________________________________________________________________________\nres3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_18[0][0]              \n__________________________________________________________________________________________________\nbn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n__________________________________________________________________________________________________\nres3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_19[0][0]              \n__________________________________________________________________________________________________\nbn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n__________________________________________________________________________________________________\nres3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_20[0][0]              \n__________________________________________________________________________________________________\nbn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n                                                                 activation_18[0][0]              \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n__________________________________________________________________________________________________\nres4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_21[0][0]              \n__________________________________________________________________________________________________\nbn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_22[0][0]              \n__________________________________________________________________________________________________\nbn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_23[0][0]              \n__________________________________________________________________________________________________\nres4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_21[0][0]              \n__________________________________________________________________________________________________\nbn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n__________________________________________________________________________________________________\nbn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n                                                                 bn4a_branch1[0][0]               \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n__________________________________________________________________________________________________\nres4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_24[0][0]              \n__________________________________________________________________________________________________\nbn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_25[0][0]              \n__________________________________________________________________________________________________\nbn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_26[0][0]              \n__________________________________________________________________________________________________\nbn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n                                                                 activation_24[0][0]              \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n__________________________________________________________________________________________________\nres4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_27[0][0]              \n__________________________________________________________________________________________________\nbn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_28[0][0]              \n__________________________________________________________________________________________________\nbn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_29[0][0]              \n__________________________________________________________________________________________________\nbn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n                                                                 activation_27[0][0]              \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n__________________________________________________________________________________________________\nres4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_30[0][0]              \n__________________________________________________________________________________________________\nbn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_31[0][0]              \n__________________________________________________________________________________________________\nbn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_32[0][0]              \n__________________________________________________________________________________________________\nbn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n                                                                 activation_30[0][0]              \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n__________________________________________________________________________________________________\nres4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_33[0][0]              \n__________________________________________________________________________________________________\nbn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_34[0][0]              \n__________________________________________________________________________________________________\nbn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_35[0][0]              \n__________________________________________________________________________________________________\nbn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n                                                                 activation_33[0][0]              \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n__________________________________________________________________________________________________\nres4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_36[0][0]              \n__________________________________________________________________________________________________\nbn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_37[0][0]              \n__________________________________________________________________________________________________\nbn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_38[0][0]              \n__________________________________________________________________________________________________\nbn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n                                                                 activation_36[0][0]              \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n__________________________________________________________________________________________________\nres5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_39[0][0]              \n__________________________________________________________________________________________________\nbn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n__________________________________________________________________________________________________\nres5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_40[0][0]              \n__________________________________________________________________________________________________\nbn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n__________________________________________________________________________________________________\nres5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_41[0][0]              \n__________________________________________________________________________________________________\nres5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_39[0][0]              \n__________________________________________________________________________________________________\nbn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n__________________________________________________________________________________________________\nbn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n__________________________________________________________________________________________________\nadd_13 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n                                                                 bn5a_branch1[0][0]               \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n__________________________________________________________________________________________________\nres5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_42[0][0]              \n__________________________________________________________________________________________________\nbn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n__________________________________________________________________________________________________\nres5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_43[0][0]              \n__________________________________________________________________________________________________\nbn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n__________________________________________________________________________________________________\nres5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_44[0][0]              \n__________________________________________________________________________________________________\nbn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_14 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n                                                                 activation_42[0][0]              \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n__________________________________________________________________________________________________\nres5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_45[0][0]              \n__________________________________________________________________________________________________\nbn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n__________________________________________________________________________________________________\nres5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_46[0][0]              \n__________________________________________________________________________________________________\nbn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n__________________________________________________________________________________________________\nres5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_47[0][0]              \n__________________________________________________________________________________________________\nbn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_15 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n                                                                 activation_45[0][0]              \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n__________________________________________________________________________________________________\naverage_pooling2d (AveragePooli (None, 4, 4, 2048)   0           activation_48[0][0]              \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 32768)        0           average_pooling2d[0][0]          \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 1024)         33555456    flatten[0][0]                    \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 11)           11275       dropout[0][0]                    \n==================================================================================================\nTotal params: 57,154,443\nTrainable params: 57,101,323\nNon-trainable params: 53,120\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def focal_loss(gamma=2., alpha=4.):\n\n    gamma = float(gamma)\n    alpha = float(alpha)\n\n    def focal_loss_fixed(y_true, y_pred):\n        \"\"\"Focal loss for multi-classification\n        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n        Notice: y_pred is probability after softmax\n        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n        Focal Loss for Dense Object Detection\n        https://arxiv.org/abs/1708.02002\n\n        Arguments:\n            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n\n        Keyword Arguments:\n            gamma {float} -- (default: {2.0})\n            alpha {float} -- (default: {4.0})\n\n        Returns:\n            [tensor] -- loss.\n        \"\"\"\n        epsilon = 1.e-9\n        y_true = tf.convert_to_tensor(y_true, tf.float32)\n        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n\n        model_out = tf.add(y_pred, epsilon)\n        ce = tf.multiply(y_true, -tf.math.log(model_out))\n        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n        reduced_fl = tf.reduce_max(fl, axis=1)\n        return tf.reduce_mean(reduced_fl)\n    return focal_loss_fixed","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:08.252957Z","iopub.execute_input":"2022-05-24T22:54:08.253212Z","iopub.status.idle":"2022-05-24T22:54:08.263217Z","shell.execute_reply.started":"2022-05-24T22:54:08.253177Z","shell.execute_reply":"2022-05-24T22:54:08.261639Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"epochs = 100\n# lr = 0.0004\n# batch_size = 64\noptimizer = optimizers.Adam()\n# optimizer = optimizers.\n# loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmetric = ['accuracy']\nmodel.compile(optimizer=optimizer,loss='categorical_crossentropy' , metrics=metric)#lloss='categorical_crossentropy' ,loss=focal_loss(alpha=11),","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:08.392050Z","iopub.execute_input":"2022-05-24T22:54:08.392707Z","iopub.status.idle":"2022-05-24T22:54:08.409592Z","shell.execute_reply.started":"2022-05-24T22:54:08.392668Z","shell.execute_reply":"2022-05-24T22:54:08.408780Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import math\nTRAIN_GENERATOR.samples//batch_size","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:09.753285Z","iopub.execute_input":"2022-05-24T22:54:09.753561Z","iopub.status.idle":"2022-05-24T22:54:09.760899Z","shell.execute_reply.started":"2022-05-24T22:54:09.753530Z","shell.execute_reply":"2022-05-24T22:54:09.760132Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"135"},"metadata":{}}]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\nhis = model.fit(TRAIN_GENERATOR,validation_data=VALIDATION_GENERATOR,epochs=epochs,batch_size=batch_size,class_weight=class_weights,\n               steps_per_epoch= math.ceil(TRAIN_GENERATOR.samples//batch_size),validation_steps=math.ceil(VALIDATION_GENERATOR.samples//batch_size),callbacks = [EarlyStopping(monitor='val_acc', patience=2)])\n\n# his = model.fit(TRAIN_GENERATOR,epochs=epochs,batch_size=batch_size,class_weight=class_weights,\n#                steps_per_epoch= math.ceil(TRAIN_GENERATOR.samples//batch_size),callbacks = [EarlyStopping(monitor='val_acc', patience=2)])\n\nmodel.save('model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T22:54:10.604123Z","iopub.execute_input":"2022-05-24T22:54:10.604675Z","iopub.status.idle":"2022-05-25T04:03:04.283204Z","shell.execute_reply.started":"2022-05-24T22:54:10.604638Z","shell.execute_reply":"2022-05-25T04:03:04.282351Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"2022-05-24 22:54:11.478972: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2022-05-24 22:54:18.062998: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"135/135 [==============================] - 181s 1s/step - loss: 8.6892 - accuracy: 0.1410 - val_loss: 2.4554 - val_accuracy: 0.0914\nEpoch 2/100\n135/135 [==============================] - 169s 1s/step - loss: 2.2458 - accuracy: 0.2923 - val_loss: 2.5114 - val_accuracy: 0.2159\nEpoch 3/100\n135/135 [==============================] - 166s 1s/step - loss: 1.8855 - accuracy: 0.4099 - val_loss: 2.7273 - val_accuracy: 0.2448\nEpoch 4/100\n135/135 [==============================] - 170s 1s/step - loss: 1.7052 - accuracy: 0.4765 - val_loss: 1.8638 - val_accuracy: 0.3726\nEpoch 5/100\n135/135 [==============================] - 168s 1s/step - loss: 1.6117 - accuracy: 0.5052 - val_loss: 1.6128 - val_accuracy: 0.4593\nEpoch 6/100\n135/135 [==============================] - 167s 1s/step - loss: 1.5717 - accuracy: 0.5227 - val_loss: 1.2462 - val_accuracy: 0.5511\nEpoch 7/100\n135/135 [==============================] - 167s 1s/step - loss: 1.5074 - accuracy: 0.5409 - val_loss: 1.4669 - val_accuracy: 0.5232\nEpoch 8/100\n135/135 [==============================] - 166s 1s/step - loss: 1.4617 - accuracy: 0.5527 - val_loss: 1.8045 - val_accuracy: 0.4470\nEpoch 9/100\n135/135 [==============================] - 168s 1s/step - loss: 1.4308 - accuracy: 0.5668 - val_loss: 1.3163 - val_accuracy: 0.5384\nEpoch 10/100\n135/135 [==============================] - 167s 1s/step - loss: 1.4167 - accuracy: 0.5690 - val_loss: 1.5506 - val_accuracy: 0.4777\nEpoch 11/100\n135/135 [==============================] - 166s 1s/step - loss: 1.3686 - accuracy: 0.5802 - val_loss: 1.3547 - val_accuracy: 0.5260\nEpoch 12/100\n135/135 [==============================] - 168s 1s/step - loss: 1.3417 - accuracy: 0.5851 - val_loss: 1.3743 - val_accuracy: 0.5592\nEpoch 13/100\n135/135 [==============================] - 166s 1s/step - loss: 1.3428 - accuracy: 0.5857 - val_loss: 1.6233 - val_accuracy: 0.5024\nEpoch 14/100\n135/135 [==============================] - 167s 1s/step - loss: 1.2840 - accuracy: 0.6071 - val_loss: 1.2869 - val_accuracy: 0.5563\nEpoch 15/100\n135/135 [==============================] - 167s 1s/step - loss: 1.2517 - accuracy: 0.6188 - val_loss: 1.8534 - val_accuracy: 0.4257\nEpoch 16/100\n135/135 [==============================] - 165s 1s/step - loss: 1.2368 - accuracy: 0.6207 - val_loss: 1.5205 - val_accuracy: 0.4645\nEpoch 17/100\n135/135 [==============================] - 166s 1s/step - loss: 1.2565 - accuracy: 0.6201 - val_loss: 1.8468 - val_accuracy: 0.4138\nEpoch 18/100\n135/135 [==============================] - 167s 1s/step - loss: 1.2292 - accuracy: 0.6196 - val_loss: 3.1820 - val_accuracy: 0.3073\nEpoch 19/100\n135/135 [==============================] - 166s 1s/step - loss: 1.2178 - accuracy: 0.6298 - val_loss: 2.0544 - val_accuracy: 0.4200\nEpoch 20/100\n135/135 [==============================] - 167s 1s/step - loss: 1.1805 - accuracy: 0.6417 - val_loss: 1.7423 - val_accuracy: 0.4981\nEpoch 21/100\n135/135 [==============================] - 170s 1s/step - loss: 1.1866 - accuracy: 0.6388 - val_loss: 2.3041 - val_accuracy: 0.3963\nEpoch 22/100\n135/135 [==============================] - 166s 1s/step - loss: 1.1632 - accuracy: 0.6471 - val_loss: 2.5250 - val_accuracy: 0.3944\nEpoch 23/100\n135/135 [==============================] - 167s 1s/step - loss: 1.1466 - accuracy: 0.6530 - val_loss: 1.1559 - val_accuracy: 0.5999\nEpoch 24/100\n135/135 [==============================] - 167s 1s/step - loss: 1.1143 - accuracy: 0.6619 - val_loss: 1.5672 - val_accuracy: 0.5241\nEpoch 25/100\n135/135 [==============================] - 169s 1s/step - loss: 1.0914 - accuracy: 0.6680 - val_loss: 1.4630 - val_accuracy: 0.5256\nEpoch 26/100\n135/135 [==============================] - 167s 1s/step - loss: 1.0628 - accuracy: 0.6768 - val_loss: 1.5753 - val_accuracy: 0.5128\nEpoch 27/100\n135/135 [==============================] - 166s 1s/step - loss: 1.0483 - accuracy: 0.6806 - val_loss: 1.3936 - val_accuracy: 0.6051\nEpoch 28/100\n135/135 [==============================] - 168s 1s/step - loss: 1.0215 - accuracy: 0.6879 - val_loss: 1.0484 - val_accuracy: 0.6378\nEpoch 29/100\n135/135 [==============================] - 166s 1s/step - loss: 1.0221 - accuracy: 0.6893 - val_loss: 1.9574 - val_accuracy: 0.5076\nEpoch 30/100\n135/135 [==============================] - 166s 1s/step - loss: 0.9913 - accuracy: 0.6980 - val_loss: 1.3662 - val_accuracy: 0.5682\nEpoch 31/100\n135/135 [==============================] - 169s 1s/step - loss: 0.9790 - accuracy: 0.7071 - val_loss: 1.4689 - val_accuracy: 0.5166\nEpoch 32/100\n135/135 [==============================] - 167s 1s/step - loss: 0.9586 - accuracy: 0.7049 - val_loss: 5.9861 - val_accuracy: 0.2069\nEpoch 33/100\n135/135 [==============================] - 166s 1s/step - loss: 1.0068 - accuracy: 0.6953 - val_loss: 1.5904 - val_accuracy: 0.5005\nEpoch 34/100\n135/135 [==============================] - 168s 1s/step - loss: 0.9753 - accuracy: 0.7056 - val_loss: 3.3042 - val_accuracy: 0.3224\nEpoch 35/100\n135/135 [==============================] - 166s 1s/step - loss: 0.9508 - accuracy: 0.7103 - val_loss: 2.2917 - val_accuracy: 0.3419\nEpoch 36/100\n135/135 [==============================] - 166s 1s/step - loss: 0.9735 - accuracy: 0.7009 - val_loss: 1.3381 - val_accuracy: 0.5720\nEpoch 37/100\n135/135 [==============================] - 166s 1s/step - loss: 0.9299 - accuracy: 0.7150 - val_loss: 2.1624 - val_accuracy: 0.4366\nEpoch 38/100\n135/135 [==============================] - 165s 1s/step - loss: 0.9461 - accuracy: 0.7127 - val_loss: 2.5914 - val_accuracy: 0.4081\nEpoch 39/100\n135/135 [==============================] - 166s 1s/step - loss: 0.8958 - accuracy: 0.7338 - val_loss: 3.7560 - val_accuracy: 0.2618\nEpoch 40/100\n135/135 [==============================] - 165s 1s/step - loss: 0.9348 - accuracy: 0.7191 - val_loss: 108.5067 - val_accuracy: 0.1288\nEpoch 41/100\n135/135 [==============================] - 168s 1s/step - loss: 0.9152 - accuracy: 0.7229 - val_loss: 4.4691 - val_accuracy: 0.2741\nEpoch 42/100\n135/135 [==============================] - 166s 1s/step - loss: 0.9482 - accuracy: 0.7096 - val_loss: 2.3295 - val_accuracy: 0.5488\nEpoch 43/100\n135/135 [==============================] - 166s 1s/step - loss: 0.8655 - accuracy: 0.7375 - val_loss: 1.1364 - val_accuracy: 0.6075\nEpoch 44/100\n135/135 [==============================] - 166s 1s/step - loss: 0.8611 - accuracy: 0.7359 - val_loss: 1.3123 - val_accuracy: 0.5890\nEpoch 45/100\n135/135 [==============================] - 164s 1s/step - loss: 0.8417 - accuracy: 0.7350 - val_loss: 36.1175 - val_accuracy: 0.3830\nEpoch 46/100\n135/135 [==============================] - 166s 1s/step - loss: 0.8515 - accuracy: 0.7418 - val_loss: 3.1980 - val_accuracy: 0.3745\nEpoch 47/100\n135/135 [==============================] - 167s 1s/step - loss: 0.8001 - accuracy: 0.7549 - val_loss: 1.4780 - val_accuracy: 0.6207\nEpoch 48/100\n135/135 [==============================] - 165s 1s/step - loss: 0.7986 - accuracy: 0.7522 - val_loss: 1.8265 - val_accuracy: 0.5384\nEpoch 49/100\n135/135 [==============================] - 167s 1s/step - loss: 0.7954 - accuracy: 0.7576 - val_loss: 3.4649 - val_accuracy: 0.5185\nEpoch 50/100\n135/135 [==============================] - 166s 1s/step - loss: 0.7509 - accuracy: 0.7684 - val_loss: 1.4867 - val_accuracy: 0.5213\nEpoch 51/100\n135/135 [==============================] - 166s 1s/step - loss: 0.7602 - accuracy: 0.7675 - val_loss: 1.4534 - val_accuracy: 0.5597\nEpoch 52/100\n135/135 [==============================] - 168s 1s/step - loss: 0.7622 - accuracy: 0.7646 - val_loss: 6.6013 - val_accuracy: 0.2571\nEpoch 53/100\n135/135 [==============================] - 166s 1s/step - loss: 0.7174 - accuracy: 0.7793 - val_loss: 2.1650 - val_accuracy: 0.5369\nEpoch 54/100\n135/135 [==============================] - 167s 1s/step - loss: 0.7347 - accuracy: 0.7708 - val_loss: 0.9744 - val_accuracy: 0.6790\nEpoch 55/100\n135/135 [==============================] - 167s 1s/step - loss: 0.7173 - accuracy: 0.7810 - val_loss: 3.8570 - val_accuracy: 0.4053\nEpoch 56/100\n135/135 [==============================] - 167s 1s/step - loss: 0.7197 - accuracy: 0.7837 - val_loss: 3.5168 - val_accuracy: 0.4223\nEpoch 57/100\n135/135 [==============================] - 167s 1s/step - loss: 0.6995 - accuracy: 0.7867 - val_loss: 2.1094 - val_accuracy: 0.5923\nEpoch 58/100\n135/135 [==============================] - 166s 1s/step - loss: 0.6985 - accuracy: 0.7841 - val_loss: 1.7778 - val_accuracy: 0.6089\nEpoch 59/100\n135/135 [==============================] - 167s 1s/step - loss: 0.6777 - accuracy: 0.7965 - val_loss: 1.5514 - val_accuracy: 0.7102\nEpoch 60/100\n135/135 [==============================] - 167s 1s/step - loss: 0.6694 - accuracy: 0.7897 - val_loss: 1.2830 - val_accuracy: 0.6103\nEpoch 61/100\n135/135 [==============================] - 167s 1s/step - loss: 0.6723 - accuracy: 0.7931 - val_loss: 20.8821 - val_accuracy: 0.3277\nEpoch 62/100\n135/135 [==============================] - 170s 1s/step - loss: 0.7039 - accuracy: 0.7909 - val_loss: 1.5210 - val_accuracy: 0.5554\nEpoch 63/100\n135/135 [==============================] - 167s 1s/step - loss: 0.7106 - accuracy: 0.7848 - val_loss: 1.2905 - val_accuracy: 0.6151\nEpoch 64/100\n135/135 [==============================] - 165s 1s/step - loss: 0.6583 - accuracy: 0.7960 - val_loss: 1.3766 - val_accuracy: 0.5975\nEpoch 65/100\n135/135 [==============================] - 166s 1s/step - loss: 0.6375 - accuracy: 0.8029 - val_loss: 1.0916 - val_accuracy: 0.6567\nEpoch 66/100\n135/135 [==============================] - 168s 1s/step - loss: 0.6071 - accuracy: 0.8143 - val_loss: 0.9747 - val_accuracy: 0.7064\nEpoch 67/100\n135/135 [==============================] - 168s 1s/step - loss: 0.6359 - accuracy: 0.8011 - val_loss: 2.8147 - val_accuracy: 0.3480\nEpoch 68/100\n135/135 [==============================] - 167s 1s/step - loss: 0.6006 - accuracy: 0.8092 - val_loss: 1.9606 - val_accuracy: 0.4967\nEpoch 69/100\n135/135 [==============================] - 167s 1s/step - loss: 0.6287 - accuracy: 0.8052 - val_loss: 2.4042 - val_accuracy: 0.4380\nEpoch 70/100\n135/135 [==============================] - 167s 1s/step - loss: 0.6006 - accuracy: 0.8177 - val_loss: 0.8501 - val_accuracy: 0.7401\nEpoch 71/100\n135/135 [==============================] - 166s 1s/step - loss: 0.5763 - accuracy: 0.8202 - val_loss: 0.8583 - val_accuracy: 0.7240\nEpoch 72/100\n135/135 [==============================] - 167s 1s/step - loss: 0.5875 - accuracy: 0.8166 - val_loss: 2.8631 - val_accuracy: 0.5421\nEpoch 73/100\n135/135 [==============================] - 168s 1s/step - loss: 0.5802 - accuracy: 0.8217 - val_loss: 0.8251 - val_accuracy: 0.7301\nEpoch 74/100\n135/135 [==============================] - 166s 1s/step - loss: 0.5534 - accuracy: 0.8272 - val_loss: 1.4550 - val_accuracy: 0.6392\nEpoch 75/100\n135/135 [==============================] - 169s 1s/step - loss: 0.5434 - accuracy: 0.8292 - val_loss: 0.9444 - val_accuracy: 0.6937\nEpoch 76/100\n135/135 [==============================] - 169s 1s/step - loss: 0.5708 - accuracy: 0.8276 - val_loss: 2.1794 - val_accuracy: 0.6307\nEpoch 77/100\n135/135 [==============================] - 168s 1s/step - loss: 0.5345 - accuracy: 0.8373 - val_loss: 2.6709 - val_accuracy: 0.4777\nEpoch 78/100\n135/135 [==============================] - 169s 1s/step - loss: 0.5214 - accuracy: 0.8369 - val_loss: 0.9524 - val_accuracy: 0.7003\nEpoch 79/100\n135/135 [==============================] - 168s 1s/step - loss: 0.5470 - accuracy: 0.8341 - val_loss: 1.3849 - val_accuracy: 0.5876\nEpoch 80/100\n135/135 [==============================] - 171s 1s/step - loss: 0.5235 - accuracy: 0.8405 - val_loss: 0.5812 - val_accuracy: 0.8021\nEpoch 81/100\n135/135 [==============================] - 168s 1s/step - loss: 0.5067 - accuracy: 0.8421 - val_loss: 1.9288 - val_accuracy: 0.7296\nEpoch 82/100\n135/135 [==============================] - 170s 1s/step - loss: 0.6138 - accuracy: 0.8110 - val_loss: 4.3984 - val_accuracy: 0.5402\nEpoch 83/100\n135/135 [==============================] - 168s 1s/step - loss: 0.5647 - accuracy: 0.8280 - val_loss: 1.3310 - val_accuracy: 0.6184\nEpoch 84/100\n135/135 [==============================] - 168s 1s/step - loss: 0.5172 - accuracy: 0.8385 - val_loss: 1.4651 - val_accuracy: 0.5729\nEpoch 85/100\n135/135 [==============================] - 169s 1s/step - loss: 0.5214 - accuracy: 0.8400 - val_loss: 1.2858 - val_accuracy: 0.6222\nEpoch 86/100\n135/135 [==============================] - 170s 1s/step - loss: 0.4936 - accuracy: 0.8476 - val_loss: 1.3579 - val_accuracy: 0.6364\nEpoch 87/100\n135/135 [==============================] - 170s 1s/step - loss: 0.5029 - accuracy: 0.8456 - val_loss: 1.4554 - val_accuracy: 0.6293\nEpoch 88/100\n135/135 [==============================] - 169s 1s/step - loss: 0.5032 - accuracy: 0.8469 - val_loss: 1.0447 - val_accuracy: 0.6847\nEpoch 89/100\n135/135 [==============================] - 168s 1s/step - loss: 0.4676 - accuracy: 0.8528 - val_loss: 2.2875 - val_accuracy: 0.5369\nEpoch 90/100\n135/135 [==============================] - 170s 1s/step - loss: 0.4874 - accuracy: 0.8475 - val_loss: 1.5483 - val_accuracy: 0.6042\nEpoch 91/100\n135/135 [==============================] - 167s 1s/step - loss: 0.4570 - accuracy: 0.8574 - val_loss: 1.3105 - val_accuracy: 0.6662\nEpoch 92/100\n135/135 [==============================] - 169s 1s/step - loss: 0.4655 - accuracy: 0.8562 - val_loss: 1.4063 - val_accuracy: 0.6326\nEpoch 93/100\n135/135 [==============================] - 170s 1s/step - loss: 0.4417 - accuracy: 0.8661 - val_loss: 1.4824 - val_accuracy: 0.6468\nEpoch 94/100\n135/135 [==============================] - 169s 1s/step - loss: 0.4505 - accuracy: 0.8626 - val_loss: 1.5525 - val_accuracy: 0.7339\nEpoch 95/100\n135/135 [==============================] - 170s 1s/step - loss: 0.4243 - accuracy: 0.8649 - val_loss: 0.8106 - val_accuracy: 0.7524\nEpoch 96/100\n135/135 [==============================] - 168s 1s/step - loss: 0.4596 - accuracy: 0.8562 - val_loss: 1.2665 - val_accuracy: 0.6813\nEpoch 97/100\n135/135 [==============================] - 169s 1s/step - loss: 0.4782 - accuracy: 0.8524 - val_loss: 14.2293 - val_accuracy: 0.5227\nEpoch 98/100\n135/135 [==============================] - 169s 1s/step - loss: 0.4243 - accuracy: 0.8656 - val_loss: 1.3944 - val_accuracy: 0.6293\nEpoch 99/100\n135/135 [==============================] - 167s 1s/step - loss: 0.4361 - accuracy: 0.8634 - val_loss: 1.0501 - val_accuracy: 0.7822\nEpoch 100/100\n135/135 [==============================] - 169s 1s/step - loss: 0.4080 - accuracy: 0.8697 - val_loss: 1.9146 - val_accuracy: 0.6212\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"TEST_DATAGEN = ImageDataGenerator(rescale = 1.0/255.)\ntestfolder= '/kaggle/input/nn22-weather-analysis-using-image-recognition/Dataset/'\nTEST_GENERATOR = TEST_DATAGEN.flow_from_directory(directory = testfolder,\n                                                    target_size = imgsize,\n                                                   shuffle=False,\n                                                  color_mode = 'rgb',\n                                                  class_mode='categorical',\n                                                   classes=['Test']\n                                                  )\nTEST_GENERATOR.reset()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T04:03:59.814345Z","iopub.execute_input":"2022-05-25T04:03:59.814753Z","iopub.status.idle":"2022-05-25T04:04:00.627579Z","shell.execute_reply.started":"2022-05-25T04:03:59.814720Z","shell.execute_reply":"2022-05-25T04:04:00.626800Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Found 1300 images belonging to 1 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"prediction = model.predict_generator(generator=TEST_GENERATOR,steps=len(TEST_GENERATOR), verbose=1)\nprediction","metadata":{"execution":{"iopub.status.busy":"2022-05-25T04:04:01.264480Z","iopub.execute_input":"2022-05-25T04:04:01.264736Z","iopub.status.idle":"2022-05-25T04:04:17.300542Z","shell.execute_reply.started":"2022-05-25T04:04:01.264706Z","shell.execute_reply":"2022-05-25T04:04:17.299765Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n  warnings.warn('`Model.predict_generator` is deprecated and '\n","output_type":"stream"},{"name":"stdout","text":"41/41 [==============================] - 16s 353ms/step\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"array([[6.1321600e-08, 6.0294719e-06, 4.7654743e-05, ..., 8.2870081e-02,\n        1.2148679e-08, 8.4554005e-01],\n       [3.9248559e-07, 4.5701286e-06, 9.4298157e-05, ..., 6.5275833e-02,\n        7.4796791e-09, 6.7587721e-01],\n       [3.0601569e-04, 9.6511483e-01, 2.5839239e-04, ..., 5.4695626e-04,\n        1.9027386e-02, 9.8634167e-03],\n       ...,\n       [4.4423019e-04, 3.3994771e-03, 1.3978196e-04, ..., 1.4270784e-04,\n        1.4166746e-03, 5.1283359e-04],\n       [2.7448614e-05, 3.9911969e-03, 2.8667433e-04, ..., 4.4872243e-02,\n        5.6613067e-06, 6.8845296e-01],\n       [2.1203633e-02, 8.5736701e-04, 2.1479634e-04, ..., 1.1856114e-03,\n        1.0264212e-03, 8.5993178e-02]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nif ince==True :    \n    pred = np.argmax(prediction[0],axis=1)\nelse :\n    pred = np.argmax(prediction,axis=1)\npred","metadata":{"execution":{"iopub.status.busy":"2022-05-25T04:04:18.409305Z","iopub.execute_input":"2022-05-25T04:04:18.410099Z","iopub.status.idle":"2022-05-25T04:04:18.419075Z","shell.execute_reply.started":"2022-05-25T04:04:18.410043Z","shell.execute_reply":"2022-05-25T04:04:18.418331Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([10, 10,  1, ...,  7, 10,  4])"},"metadata":{}}]},{"cell_type":"code","source":"pred.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-25T04:04:21.796333Z","iopub.execute_input":"2022-05-25T04:04:21.796906Z","iopub.status.idle":"2022-05-25T04:04:21.801849Z","shell.execute_reply.started":"2022-05-25T04:04:21.796851Z","shell.execute_reply":"2022-05-25T04:04:21.801126Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(1300,)"},"metadata":{}}]},{"cell_type":"code","source":"def imagenamsfix(imgnames) :\n\n    imgnames = np.char.split(imgnames,sep='/')\n    names = []\n    for i in imgnames :\n        names.append(i[-1])\n    return np.array(names)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T04:04:22.929251Z","iopub.execute_input":"2022-05-25T04:04:22.929677Z","iopub.status.idle":"2022-05-25T04:04:22.934600Z","shell.execute_reply.started":"2022-05-25T04:04:22.929644Z","shell.execute_reply":"2022-05-25T04:04:22.933786Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfilenames=TEST_GENERATOR.filenames\nsub = pd.DataFrame({\"image_name\":imagenamsfix(filenames),\"label\":pred})\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T04:04:24.508129Z","iopub.execute_input":"2022-05-25T04:04:24.508389Z","iopub.status.idle":"2022-05-25T04:04:24.519227Z","shell.execute_reply.started":"2022-05-25T04:04:24.508357Z","shell.execute_reply":"2022-05-25T04:04:24.517286Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission2.csv' , index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T04:06:10.095588Z","iopub.execute_input":"2022-05-25T04:06:10.096331Z","iopub.status.idle":"2022-05-25T04:06:10.105152Z","shell.execute_reply.started":"2022-05-25T04:06:10.096291Z","shell.execute_reply":"2022-05-25T04:06:10.104272Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"execution":{"iopub.status.busy":"2022-05-25T04:04:30.204911Z","iopub.execute_input":"2022-05-25T04:04:30.205406Z","iopub.status.idle":"2022-05-25T04:04:30.224320Z","shell.execute_reply.started":"2022-05-25T04:04:30.205369Z","shell.execute_reply":"2022-05-25T04:04:30.223578Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"         image_name  label\n0        test_1.jpg     10\n1       test_10.jpg     10\n2      test_100.jpg      1\n3     test_1000.jpg      7\n4     test_1001.jpg      4\n...             ...    ...\n1295   test_995.jpg      8\n1296   test_996.jpg      4\n1297   test_997.jpg      7\n1298   test_998.jpg     10\n1299   test_999.jpg      4\n\n[1300 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_1.jpg</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_10.jpg</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_100.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_1000.jpg</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_1001.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1295</th>\n      <td>test_995.jpg</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1296</th>\n      <td>test_996.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1297</th>\n      <td>test_997.jpg</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1298</th>\n      <td>test_998.jpg</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1299</th>\n      <td>test_999.jpg</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>1300 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}